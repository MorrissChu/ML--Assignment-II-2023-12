{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入套件\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import collections\n",
    "import random\n",
    "import time\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((58592, 42), (58592,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 讀取資料\n",
    "train_data = pd.read_csv(\"/Users/zhuxinrong/Desktop/ML/Dataset/train.csv\")\n",
    "y = train_data[\"is_claim\"]\n",
    "df = train_data.drop([\"policy_id\", \"is_claim\"], axis=1)\n",
    "df.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View type of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(58592, 44)\n",
      "policy_id                            object\n",
      "policy_tenure                       float64\n",
      "age_of_car                          float64\n",
      "age_of_policyholder                 float64\n",
      "area_cluster                         object\n",
      "population_density                    int64\n",
      "make                                  int64\n",
      "segment                              object\n",
      "model                                object\n",
      "fuel_type                            object\n",
      "max_torque                           object\n",
      "max_power                            object\n",
      "engine_type                          object\n",
      "airbags                               int64\n",
      "is_esc                               object\n",
      "is_adjustable_steering               object\n",
      "is_tpms                              object\n",
      "is_parking_sensors                   object\n",
      "is_parking_camera                    object\n",
      "rear_brakes_type                     object\n",
      "displacement                          int64\n",
      "cylinder                              int64\n",
      "transmission_type                    object\n",
      "gear_box                              int64\n",
      "steering_type                        object\n",
      "turning_radius                      float64\n",
      "length                                int64\n",
      "width                                 int64\n",
      "height                                int64\n",
      "gross_weight                          int64\n",
      "is_front_fog_lights                  object\n",
      "is_rear_window_wiper                 object\n",
      "is_rear_window_washer                object\n",
      "is_rear_window_defogger              object\n",
      "is_brake_assist                      object\n",
      "is_power_door_locks                  object\n",
      "is_central_locking                   object\n",
      "is_power_steering                    object\n",
      "is_driver_seat_height_adjustable     object\n",
      "is_day_night_rear_view_mirror        object\n",
      "is_ecw                               object\n",
      "is_speed_alert                       object\n",
      "ncap_rating                           int64\n",
      "is_claim                              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 檢查資料是否有NA值並刪除id欄位\n",
    "print(train_data.isna().sum().sum())\n",
    "print(train_data.shape)\n",
    "print(train_data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義資料預處理函數\n",
    "def preprocess(data):\n",
    "    dt = data.copy()\n",
    "    cat = dt.select_dtypes(\"object\")\n",
    "    conti = dt.select_dtypes([\"int64\", \"float64\"])\n",
    "    cat_col = cat.columns\n",
    "    conti_col = conti.columns\n",
    "    for col in cat_col:\n",
    "        num = cat[col].unique()\n",
    "        if len(num)==2:\n",
    "            # \"Yes\"==1且\"No\"==0\n",
    "            if \"Yes\" in num:\n",
    "                dt[col] = dt[col].map({\"Yes\": 1, \"No\": 0})\n",
    "            # 無順序之類別則用one hot encoding來轉換\n",
    "            elif \"Drum\" in num:\n",
    "                dt[\"is_Drum\"] = dt[col].map({\"Drum\": 1, \"Disc\": 0})\n",
    "                dt[\"is_Disc\"] = dt[col].map({\"Disc\": 1, \"Drum\": 0})\n",
    "                dt = dt.drop(col, axis=1)\n",
    "            # 無順序之類別則用one hot encoding來轉換\n",
    "            else:\n",
    "                dt[\"is_Manual\"] = dt[col].map({\"Manual\": 1, \"Automatic\": 0})\n",
    "                dt[\"is_Automatic\"] = dt[col].map({\"Automatic\": 1, \"Manual\": 0})\n",
    "                dt = dt.drop(col, axis=1)\n",
    "        elif len(num)==3:\n",
    "            # 無順序之類別則用one hot encoding來轉換\n",
    "            if col==\"fuel_type\":\n",
    "                dt[\"is_CNG\"] = dt[col].map({\"CNG\": 1, \"Petrol\": 0, \"Diesel\": 0})\n",
    "                dt[\"is_Petrol\"] = dt[col].map({\"Petrol\": 1, \"CNG\": 0, \"Diesel\": 0})\n",
    "                dt = dt.drop(col, axis=1)\n",
    "            # 無順序之類別則用one hot encoding來轉換\n",
    "            else:\n",
    "                dt[\"is_Power\"] = dt[col].map({\"Power\": 1, \"Electric\": 0, \"Manual\": 0})\n",
    "                dt[\"is_Electric\"] = dt[col].map({\"Electric\": 1, \"Power\": 0, \"Manual\": 0})\n",
    "                dt = dt.drop(col, axis=1)\n",
    "        else:\n",
    "            # 取出扭力值\n",
    "            if col==\"max_torque\":\n",
    "                dic = {}\n",
    "                for n in num:\n",
    "                    dic.update({n: float(re.findall(r\"-?\\d+\\.?\\d*\", n)[0])})\n",
    "                dt[col] = dt[col].map(dic)\n",
    "                max = dt[col].max()\n",
    "                min = dt[col].min()\n",
    "                dt[col] = (dt[col]-min)/(max-min)\n",
    "            # 取出馬力值\n",
    "            elif col==\"max_power\":\n",
    "                dic = {}\n",
    "                for n in num:\n",
    "                    dic.update({n: float(re.findall(r\"-?\\d+\\.?\\d*\", n)[0])})\n",
    "                dt[col] = dt[col].map(dic)\n",
    "                max = dt[col].max()\n",
    "                min = dt[col].min()\n",
    "                dt[col] = (dt[col]-min)/(max-min)\n",
    "            # 其餘變數皆使用frequency encoding來轉換並標準化\n",
    "            else:\n",
    "                c = collections.Counter(dt[col])\n",
    "                dt[col] = dt[col].map(c)\n",
    "                max = dt[col].max()\n",
    "                min = dt[col].min()\n",
    "                dt[col] = (dt[col]-min)/(max-min)\n",
    "                \n",
    "    # 對所有連續變數標準化\n",
    "    for col in conti_col:\n",
    "        max = dt[col].max()\n",
    "        min = dt[col].min()\n",
    "        dt[col] = (dt[col]-min)/(max-min)\n",
    "       \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義分割資料函數\n",
    "def split_data(df, y, valid_proportion, test_proportion, random_state):\n",
    "    size = df.shape[0]\n",
    "    test_num = int(size*test_proportion)\n",
    "    valid_num = int(size*valid_proportion)\n",
    "    train_num = size-test_num-valid_num\n",
    "    order = np.array(df.index)\n",
    "    random.seed(random_state)\n",
    "    random.shuffle(order)\n",
    "    train_idx = order[:train_num]\n",
    "    valid_idx = order[train_num:valid_num+train_num]\n",
    "    test_idx = order[valid_num+train_num:]\n",
    "\n",
    "    train_x, valid_x, test_x = df.loc[train_idx], df.loc[valid_idx], df.loc[test_idx]\n",
    "    train_y, valid_y, test_y = y.loc[train_idx], y.loc[valid_idx], y.loc[test_idx]\n",
    "    return train_x, valid_x, test_x, train_y, valid_y, test_y\n",
    "\n",
    "# 定義 RBF 函數\n",
    "def RBF(x1, x2, gamma=1):\n",
    "    diff = x1-x2\n",
    "    # rbf = np.exp(-gamma * np.dot(diff, diff))\n",
    "    rbf = np.exp(-gamma * (diff**2))\n",
    "    return rbf\n",
    "\n",
    "\n",
    "# 建立 kernel 矩陣\n",
    "def kernel_matrix(X, kernel_func, **kwargs):\n",
    "    col = X.columns\n",
    "    newft = {}\n",
    "    n = 0\n",
    "    for i in trange(len(col)):\n",
    "        for j in range(i+1, len(col)):\n",
    "            name = \"Kernel_\"+str(n)\n",
    "            newft[name] = kernel_func(X[col[i]], X[col[j]], **kwargs)\n",
    "            n += 1\n",
    "    new_df = pd.DataFrame(newft)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 1062.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy_tenure</th>\n",
       "      <th>age_of_car</th>\n",
       "      <th>age_of_policyholder</th>\n",
       "      <th>area_cluster</th>\n",
       "      <th>population_density</th>\n",
       "      <th>make</th>\n",
       "      <th>segment</th>\n",
       "      <th>model</th>\n",
       "      <th>max_torque</th>\n",
       "      <th>max_power</th>\n",
       "      <th>...</th>\n",
       "      <th>is_Manual</th>\n",
       "      <th>is_Automatic</th>\n",
       "      <th>is_Power</th>\n",
       "      <th>is_Electric</th>\n",
       "      <th>Kernel_0</th>\n",
       "      <th>Kernel_1</th>\n",
       "      <th>Kernel_2</th>\n",
       "      <th>Kernel_3</th>\n",
       "      <th>Kernel_4</th>\n",
       "      <th>Kernel_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.368130</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.100332</td>\n",
       "      <td>0.064260</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.941947</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997961</td>\n",
       "      <td>0.998584</td>\n",
       "      <td>0.997961</td>\n",
       "      <td>0.998584</td>\n",
       "      <td>0.999943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.480580</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.121622</td>\n",
       "      <td>0.533998</td>\n",
       "      <td>0.365231</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.941947</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997961</td>\n",
       "      <td>0.998584</td>\n",
       "      <td>0.997961</td>\n",
       "      <td>0.998584</td>\n",
       "      <td>0.999943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.442377</td>\n",
       "      <td>0.051764</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.941947</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997961</td>\n",
       "      <td>0.998584</td>\n",
       "      <td>0.997961</td>\n",
       "      <td>0.998584</td>\n",
       "      <td>0.999943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.643904</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.041048</td>\n",
       "      <td>0.291660</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137270</td>\n",
       "      <td>0.049160</td>\n",
       "      <td>0.278947</td>\n",
       "      <td>0.617179</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999481</td>\n",
       "      <td>0.997967</td>\n",
       "      <td>0.995904</td>\n",
       "      <td>0.995401</td>\n",
       "      <td>0.998298</td>\n",
       "      <td>0.988152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.425902</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.507198</td>\n",
       "      <td>0.470987</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.941947</td>\n",
       "      <td>0.137813</td>\n",
       "      <td>0.163158</td>\n",
       "      <td>0.342308</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>0.982090</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.985680</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.983750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58587</th>\n",
       "      <td>0.252782</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.116270</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.941947</td>\n",
       "      <td>0.137813</td>\n",
       "      <td>0.163158</td>\n",
       "      <td>0.342308</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>0.982090</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.985680</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.983750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58588</th>\n",
       "      <td>0.858671</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.262163</td>\n",
       "      <td>0.102516</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.941947</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997961</td>\n",
       "      <td>0.998584</td>\n",
       "      <td>0.997961</td>\n",
       "      <td>0.998584</td>\n",
       "      <td>0.999943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58589</th>\n",
       "      <td>0.831862</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>0.507198</td>\n",
       "      <td>0.470987</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.941947</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997961</td>\n",
       "      <td>0.998584</td>\n",
       "      <td>0.997961</td>\n",
       "      <td>0.998584</td>\n",
       "      <td>0.999943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58590</th>\n",
       "      <td>0.884975</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.116270</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919643</td>\n",
       "      <td>0.278947</td>\n",
       "      <td>0.617179</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998932</td>\n",
       "      <td>0.997967</td>\n",
       "      <td>0.995904</td>\n",
       "      <td>0.999846</td>\n",
       "      <td>0.990682</td>\n",
       "      <td>0.988152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58591</th>\n",
       "      <td>0.087304</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.116270</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.748845</td>\n",
       "      <td>0.936236</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999693</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999609</td>\n",
       "      <td>0.999609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58592 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       policy_tenure  age_of_car  age_of_policyholder  area_cluster  \\\n",
       "0           0.368130        0.05             0.500000      0.100332   \n",
       "1           0.480580        0.02             0.121622      0.533998   \n",
       "2           0.601457        0.02             0.135135      0.442377   \n",
       "3           0.643904        0.11             0.202703      0.041048   \n",
       "4           0.425902        0.11             0.486486      0.507198   \n",
       "...              ...         ...                  ...           ...   \n",
       "58587       0.252782        0.13             0.500000      1.000000   \n",
       "58588       0.858671        0.02             0.324324      0.262163   \n",
       "58589       0.831862        0.05             0.229730      0.507198   \n",
       "58590       0.884975        0.14             0.378378      1.000000   \n",
       "58591       0.087304        0.02             0.216216      1.000000   \n",
       "\n",
       "       population_density  make   segment     model  max_torque  max_power  \\\n",
       "0                0.064260  0.00  0.941947  1.000000    0.000000   0.000000   \n",
       "1                0.365231  0.00  0.941947  1.000000    0.000000   0.000000   \n",
       "2                0.051764  0.00  0.941947  1.000000    0.000000   0.000000   \n",
       "3                0.291660  0.00  0.137270  0.049160    0.278947   0.617179   \n",
       "4                0.470987  0.25  0.941947  0.137813    0.163158   0.342308   \n",
       "...                   ...   ...       ...       ...         ...        ...   \n",
       "58587            0.116270  0.25  0.941947  0.137813    0.163158   0.342308   \n",
       "58588            0.102516  0.00  0.941947  1.000000    0.000000   0.000000   \n",
       "58589            0.470987  0.00  0.941947  1.000000    0.000000   0.000000   \n",
       "58590            0.116270  0.00  1.000000  0.919643    0.278947   0.617179   \n",
       "58591            0.116270  0.50  0.748845  0.936236    1.000000   0.937051   \n",
       "\n",
       "       ...  is_Manual  is_Automatic  is_Power  is_Electric  Kernel_0  \\\n",
       "0      ...          1             0         1            0  1.000000   \n",
       "1      ...          1             0         1            0  1.000000   \n",
       "2      ...          1             0         1            0  1.000000   \n",
       "3      ...          0             1         0            1  0.999481   \n",
       "4      ...          0             1         0            1  0.999795   \n",
       "...    ...        ...           ...       ...          ...       ...   \n",
       "58587  ...          0             1         0            1  0.999795   \n",
       "58588  ...          1             0         1            0  1.000000   \n",
       "58589  ...          1             0         1            0  1.000000   \n",
       "58590  ...          1             0         0            1  0.998932   \n",
       "58591  ...          0             1         1            0  0.999995   \n",
       "\n",
       "       Kernel_1  Kernel_2  Kernel_3  Kernel_4  Kernel_5  \n",
       "0      0.997961  0.998584  0.997961  0.998584  0.999943  \n",
       "1      0.997961  0.998584  0.997961  0.998584  0.999943  \n",
       "2      0.997961  0.998584  0.997961  0.998584  0.999943  \n",
       "3      0.997967  0.995904  0.995401  0.998298  0.988152  \n",
       "4      0.982090  0.999959  0.985680  0.999938  0.983750  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "58587  0.982090  0.999959  0.985680  0.999938  0.983750  \n",
       "58588  0.997961  0.998584  0.997961  0.998584  0.999943  \n",
       "58589  0.997961  0.998584  0.997961  0.998584  0.999943  \n",
       "58590  0.997967  0.995904  0.999846  0.990682  0.988152  \n",
       "58591  0.999995  0.999693  1.000000  0.999609  0.999609  \n",
       "\n",
       "[58592 rows x 52 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將資料分割成訓練集與測試集\n",
    "df = preprocess(df)\n",
    "\n",
    "# 擴展特徵空間至高維度（挑選相關性最高的幾個特徵來進行 kernel 方法）\n",
    "kernel = kernel_matrix(df[[\"displacement\", \"length\", \"turning_radius\", \"width\"]], RBF, gamma=0.1)\n",
    "\n",
    "# 合併新特徵至元特徵集\n",
    "new_df = df.join(kernel)\n",
    "new_df#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((41015, 52), (5859, 52), (11718, 52), (41015,), (5859,), (11718,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 切割訓練集、驗證集與測試集\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test = split_data(new_df, y, valid_proportion=0.1, test_proportion=0.2, random_state=1121225)\n",
    "# x_train, x_valid, x_test, y_train, y_valid, y_test = split_data(df, y, valid_proportion=0.1, test_proportion=0.2, random_state=1121225)\n",
    "x_train.shape, x_valid.shape, x_test.shape, y_train.shape, y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Application of Kernel Methods in Ensemble Learning Across Various Learners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest Classifier\n",
    "class RandomForestClassifier:\n",
    "    def __init__(self, threshold=15) -> None:\n",
    "        self.threshold = threshold\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Distinguish categorical and continuous features\n",
    "    def determine_type_of_feature(self, df):\n",
    "        \n",
    "        feature_types = []\n",
    "        n_unique_values_treshold = self.threshold\n",
    "        for feature in df.columns:\n",
    "            if feature != \"is_claim\": # \"label\"\n",
    "                unique_values = df[feature].unique()\n",
    "                example_value = unique_values[0]\n",
    "\n",
    "                if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_treshold):\n",
    "                    feature_types.append(\"categorical\")\n",
    "                else:\n",
    "                    feature_types.append(\"continuous\")\n",
    "        \n",
    "        return feature_types\n",
    "\n",
    "\n",
    "    # Accuracy\n",
    "    def calculate_accuracy(self, y_true, y_pred):\n",
    "        acc = (y_true==y_pred).mean()\n",
    "        return acc\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------\n",
    "    # 1. Decision Tree functions with helper function\n",
    "\n",
    "    # 1.1 Data pure\n",
    "    def check_purity(self, data):\n",
    "        \n",
    "        label_column = data[:, -1]\n",
    "        unique_classes = np.unique(label_column)\n",
    "\n",
    "        if len(unique_classes) == 1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "        \n",
    "    # 1.2 Classify\n",
    "    def classify_data(self, data):\n",
    "        \n",
    "        label_column = data[:, -1]\n",
    "        unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "\n",
    "        index = counts_unique_classes.argmax()\n",
    "        classification = unique_classes[index]\n",
    "        \n",
    "        return classification\n",
    "\n",
    "\n",
    "    # 1.3 Potential splits\n",
    "    def get_potential_splits(self, data, random_subspace):\n",
    "        \n",
    "        potential_splits = {}\n",
    "        _, n_columns = data.shape\n",
    "        column_indices = list(range(n_columns - 1))    # excluding the last column which is the label\n",
    "        \n",
    "        if random_subspace and random_subspace <= len(column_indices):\n",
    "            column_indices = random.sample(population=column_indices, k=random_subspace)\n",
    "        \n",
    "        for column_index in column_indices:          \n",
    "            values = data[:, column_index]\n",
    "            unique_values = np.unique(values)\n",
    "            \n",
    "            potential_splits[column_index] = unique_values\n",
    "        \n",
    "        return potential_splits\n",
    "\n",
    "\n",
    "    # 1.4 Lowest Overall Entropy\n",
    "    def calculate_entropy(self, data):\n",
    "        \n",
    "        label_column = data[:, -1]\n",
    "        _, counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "        probabilities = counts / counts.sum()\n",
    "        entropy = sum(probabilities * -np.log2(probabilities))\n",
    "        \n",
    "        return entropy\n",
    "\n",
    "\n",
    "    def calculate_overall_entropy(self, data_below, data_above):\n",
    "        \n",
    "        n = len(data_below) + len(data_above)\n",
    "        p_data_below = len(data_below) / n\n",
    "        p_data_above = len(data_above) / n\n",
    "\n",
    "        overall_entropy =  (p_data_below * self.calculate_entropy(data_below) \n",
    "                        + p_data_above * self.calculate_entropy(data_above))\n",
    "        \n",
    "        return overall_entropy\n",
    "\n",
    "\n",
    "    def determine_best_split(self, data, potential_splits):\n",
    "        \n",
    "        overall_entropy = 9999\n",
    "        for column_index in potential_splits:\n",
    "            for value in potential_splits[column_index]:\n",
    "                data_below, data_above = self.split_data(data, split_column=column_index, split_value=value)\n",
    "                current_overall_entropy = self.calculate_overall_entropy(data_below, data_above)\n",
    "                \n",
    "                if current_overall_entropy <= overall_entropy:\n",
    "                    overall_entropy = current_overall_entropy\n",
    "                    best_split_column = column_index\n",
    "                    best_split_value = value\n",
    "        \n",
    "        return best_split_column, best_split_value\n",
    "\n",
    "\n",
    "    # 1.5 Split data\n",
    "    def split_data(self, data, split_column, split_value):\n",
    "        \n",
    "        split_column_values = data[:, split_column]\n",
    "\n",
    "        type_of_feature = FEATURE_TYPES[split_column]\n",
    "        if type_of_feature == \"continuous\":\n",
    "            data_below = data[split_column_values <= split_value]\n",
    "            data_above = data[split_column_values >  split_value]\n",
    "        \n",
    "        # feature is categorical   \n",
    "        else:\n",
    "            data_below = data[split_column_values == split_value]\n",
    "            data_above = data[split_column_values != split_value]\n",
    "        \n",
    "        return data_below, data_above\n",
    "\n",
    "\n",
    "    # 2. Decision Tree Algorithm\n",
    "    def decision_tree_algorithm(self, df, counter=0, min_samples=2, max_depth=5, random_subspace=None):\n",
    "        \n",
    "        # data preparations\n",
    "        if counter == 0:\n",
    "            global COLUMN_HEADERS, FEATURE_TYPES\n",
    "            COLUMN_HEADERS = df.columns\n",
    "            FEATURE_TYPES = self.determine_type_of_feature(df)\n",
    "            data = df.values\n",
    "        else:\n",
    "            data = df           \n",
    "        \n",
    "        \n",
    "        # base cases\n",
    "        if (self.check_purity(data)) or (len(data) < min_samples) or (counter == max_depth):\n",
    "            classification = self.classify_data(data)\n",
    "            \n",
    "            return classification\n",
    "\n",
    "        \n",
    "        # recursive part\n",
    "        else:    \n",
    "            counter += 1\n",
    "\n",
    "            # helper functions \n",
    "            potential_splits = self.get_potential_splits(data, random_subspace)\n",
    "            split_column, split_value = self.determine_best_split(data, potential_splits)\n",
    "            data_below, data_above = self.split_data(data, split_column, split_value)\n",
    "            \n",
    "            # check for empty data\n",
    "            if len(data_below) == 0 or len(data_above) == 0:\n",
    "                classification = self.classify_data(data)\n",
    "                return classification\n",
    "            \n",
    "            # determine question\n",
    "            feature_name = COLUMN_HEADERS[split_column]\n",
    "            type_of_feature = FEATURE_TYPES[split_column]\n",
    "            if type_of_feature == \"continuous\":\n",
    "                question = \"{} <= {}\".format(feature_name, split_value)\n",
    "                \n",
    "            # feature is categorical\n",
    "            else:\n",
    "                question = \"{} = {}\".format(feature_name, split_value)\n",
    "            \n",
    "            # instantiate sub-tree\n",
    "            sub_tree = {question: []}\n",
    "            \n",
    "            # find answers (recursion)\n",
    "            yes_answer = self.decision_tree_algorithm(data_below, counter, min_samples, max_depth, random_subspace)\n",
    "            no_answer = self.decision_tree_algorithm(data_above, counter, min_samples, max_depth, random_subspace)\n",
    "            \n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "            \n",
    "            return sub_tree\n",
    "\n",
    "\n",
    "    # 3. Make predictions\n",
    "    # 3.1 One example\n",
    "    def predict_example(self, example, tree):\n",
    "            \n",
    "        question = list(tree.keys())[0]\n",
    "        feature_name, comparison_operator, value = question.split(\" \")\n",
    "\n",
    "        # ask question\n",
    "        if comparison_operator == \"<=\":\n",
    "            if example[feature_name] <= float(value):\n",
    "                answer = tree[question][0]\n",
    "            else:\n",
    "                answer = tree[question][1]\n",
    "        \n",
    "        # feature is categorical\n",
    "        else:\n",
    "            if str(example[feature_name]) == value:\n",
    "                answer = tree[question][0]\n",
    "            else:\n",
    "                answer = tree[question][1]\n",
    "\n",
    "        # base case\n",
    "        if not isinstance(answer, dict):\n",
    "            return answer\n",
    "        \n",
    "        # recursive part\n",
    "        else:\n",
    "            residual_tree = answer\n",
    "            return self.predict_example(example, residual_tree)\n",
    "\n",
    "        \n",
    "    # 3.2 All examples of the test data\n",
    "    def decision_tree_predictions(self, test_df, tree):\n",
    "        predictions = test_df.apply(self.predict_example, args=(tree,), axis=1)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "    def random_forest_algorithm(self, train_df, n_trees, n_features, dt_max_depth):\n",
    "        forest = []\n",
    "        for i in trange(n_trees):\n",
    "            col = random.sample(list(train_df.iloc[:,:-1].columns), n_features)\n",
    "            tree = self.decision_tree_algorithm(train_df[col], max_depth=dt_max_depth)\n",
    "            forest.append(tree)\n",
    "\n",
    "        return forest\n",
    "\n",
    "    def random_forest_predictions(self, test_df, forest):\n",
    "        df_predictions = {}\n",
    "        for i in range(len(forest)):\n",
    "            column_name = \"tree_{}\".format(i)\n",
    "            predictions = self.decision_tree_predictions(test_df, tree=forest[i])\n",
    "            df_predictions[column_name] = predictions\n",
    "\n",
    "        df_predictions = pd.DataFrame(df_predictions)\n",
    "        \n",
    "        return df_predictions\n",
    "    \n",
    "    def EL_random_forest_predictions(self, test_df, forest):\n",
    "        df_predictions = {}\n",
    "        for i in range(len(forest)):\n",
    "            column_name = \"tree_{}\".format(i)\n",
    "            predictions = self.decision_tree_predictions(test_df, tree=forest[i])\n",
    "            df_predictions[column_name] = predictions\n",
    "\n",
    "        df_predictions = pd.DataFrame(df_predictions)\n",
    "        random_forest_predictions = df_predictions.mode(axis=1)[0]\n",
    "\n",
    "        return random_forest_predictions\n",
    "    \n",
    "    def each_trees_accuracy(self, X, trees):\n",
    "        preds = self.random_forest_predictions(test_df=X, forest=trees)\n",
    "        y = X.iloc[:,-1]\n",
    "        accuracy = {}\n",
    "        for col in preds.columns:\n",
    "            acc = self.calculate_accuracy(y, preds[col])\n",
    "            accuracy[col] = acc\n",
    "            \n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier()\n",
    "\n",
    "# 將特徵與label合併\n",
    "train_x_y = pd.concat([x_train, y_train], axis=1)\n",
    "valid_x_y = pd.concat([x_valid, y_valid], axis=1)\n",
    "test_x_y = pd.concat([x_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([38371,  2644]))\n",
      "(array([0, 1]), array([5484,  375]))\n",
      "(array([0, 1]), array([10989,   729]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(train_x_y[\"is_claim\"], return_counts=True))\n",
    "print(np.unique(valid_x_y[\"is_claim\"], return_counts=True))\n",
    "print(np.unique(test_x_y[\"is_claim\"], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [20:22<00:00, 244.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "執行時間：1222.9663071632385秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 訓練隨機森林模型並預測\n",
    "start = time.time()\n",
    "forest = RFC.random_forest_algorithm(train_x_y, n_trees=5, n_features=40, dt_max_depth=10)\n",
    "print(\"執行時間：{}秒\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tree_0': 0.27342549923195086,\n",
       " 'tree_1': 0.1300563236047107,\n",
       " 'tree_2': 0.41235705751834784,\n",
       " 'tree_3': 0.037037037037037035,\n",
       " 'tree_4': 0.23758320532514082}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 驗證集準確率\n",
    "WL_acc = RFC.each_trees_accuracy(valid_x_y, forest)\n",
    "WL_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 layers MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, layers, output_size, random_seed):\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "        model = {}  #Dictionary\n",
    "\n",
    "        #First Layer\n",
    "        model['W1'] = np.random.randn(input_size, layers)\n",
    "        model['b1'] = np.zeros((1, layers))\n",
    "\n",
    "        #Second/Output Layer\n",
    "        model['W2'] = np.random.randn(layers, output_size)\n",
    "        model['b2'] = np.zeros((1, output_size))\n",
    "        \n",
    "\n",
    "        self.model = model\n",
    "        self.activation_outputs = None\n",
    "\n",
    "# -------------------- activation function ---------------------- #\n",
    "    def softmax(self, a):\n",
    "        e_pa = np.exp(a)\n",
    "        ans = e_pa / np.sum(e_pa, axis=1, keepdims=True)\n",
    "        return ans\n",
    "\n",
    "    def Sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# ---------------------------- training & prediction --------------------------------- #\n",
    "    \n",
    "    # NN process\n",
    "    def forward(self, x):\n",
    "\n",
    "        W1, W2 = self.model['W1'], self.model['W2']\n",
    "        b1, b2 = self.model['b1'], self.model['b2']\n",
    "\n",
    "        z1 = np.dot(x, W1) + b1\n",
    "        a1 = np.tanh(z1)\n",
    "\n",
    "        z2 = np.dot(a1, W2) + b2\n",
    "        y_ = self.Sigmoid(z2)\n",
    "\n",
    "        self.activation_outputs = (a1, y_)\n",
    "        return y_\n",
    "\n",
    "    # iteration with renew weights\n",
    "    def backward(self, x, y, learning_rate=0.001):\n",
    "        W1, W2 = self.model['W1'], self.model['W2']\n",
    "\n",
    "        a1, y_ = self.activation_outputs\n",
    "\n",
    "        delta2 = y_ - y\n",
    "        dw2 = np.dot(a1.T, delta2)\n",
    "        db2 = np.sum(delta2, axis=0)\n",
    "\n",
    "        delta1 = (1 - np.square(a1)) * np.dot(delta2, W2.T)\n",
    "        dw1 = np.dot(x.T, delta1)\n",
    "        db1 = np.sum(delta1, axis=0)\n",
    "\n",
    "        #Update the Model Parameters using Gradient Descent\n",
    "        self.model[\"W1\"] -= learning_rate * dw1\n",
    "        self.model['b1'] -= learning_rate * db1\n",
    "\n",
    "        self.model[\"W2\"] -= learning_rate * dw2\n",
    "        self.model['b2'] -= learning_rate * db2\n",
    "\n",
    "    # prediction\n",
    "    def predict(self, x):\n",
    "        y_out = self.forward(x)\n",
    "        return np.argmax(y_out, axis=1)\n",
    "\n",
    "    def summary(self):\n",
    "        W1, W2 = self.model['W1'], self.model['W2']\n",
    "        a1, y_ = self.activation_outputs\n",
    "\n",
    "        print(\"W1 \", W1.shape)\n",
    "        print(\"A1 \", a1.shape)\n",
    "\n",
    "        print(\"W2 \", W2.shape)\n",
    "        print(\"Y_ \", y_.shape)\n",
    "\n",
    "    # loss function\n",
    "    def loss(self, y_oht, p):\n",
    "        l = -np.mean(y_oht * np.log(p))\n",
    "        return l\n",
    "\n",
    "    # one hot encoding function\n",
    "    def one_hot(self, y, depth):\n",
    "\n",
    "        m = y.shape[0]\n",
    "        y_oht = np.zeros((m, depth))\n",
    "        y_oht[np.arange(m), y] = 1\n",
    "        return y_oht\n",
    "    \n",
    "    # training\n",
    "    def train(self, X, Y, epochs, learning_rate, logs=True):\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        training_loss = []\n",
    "\n",
    "        classes = 2\n",
    "        Y_OHT = self.one_hot(Y, classes)\n",
    "\n",
    "        for ix in range(epochs):\n",
    "\n",
    "            Y_ = self.forward(X)\n",
    "            l = self.loss(Y_OHT, Y_)\n",
    "            training_loss.append(l)\n",
    "            self.backward(X, Y_OHT, learning_rate)\n",
    "\n",
    "            if (logs and ix%50==0):\n",
    "                print(\"Epoch %d Loss %.4f\" % (ix, l))\n",
    "\n",
    "        return training_loss\n",
    "    \n",
    "    # calculate accuracy\n",
    "    def accuracy(self, y, pred):\n",
    "        acc = np.sum(pred == y) / y.shape[0]\n",
    "        return acc\n",
    "\n",
    "# ------------------------------------------------- ensemble learning ------------------------------------------------- #\n",
    "    def EL_forward(self, x, m):\n",
    "\n",
    "        W1, W2 = m['W1'], m['W2']\n",
    "        b1, b2 = m['b1'], m['b2']\n",
    "\n",
    "        z1 = np.dot(x, W1) + b1\n",
    "        a1 = np.tanh(z1)\n",
    "\n",
    "        z2 = np.dot(a1, W2) + b2\n",
    "        y_ = self.Sigmoid(z2)\n",
    "\n",
    "        self.activation_outputs = (a1, y_)\n",
    "        return y_\n",
    "    \n",
    "    def EL_predict(self, x, m):\n",
    "        y_out = self.EL_forward(x, m)\n",
    "        return np.argmax(y_out, axis=1)\n",
    "\n",
    "    def Ensemble_Learning(self, X, Y, epochs, learning_rate, model_number, n_features, logs=True):\n",
    "        model_weights = []\n",
    "        column = []\n",
    "        losses = []\n",
    "        for times in trange(model_number):\n",
    "            col = random.sample(list(X.columns), n_features)\n",
    "            loss = self.train(X[col], Y, epochs, learning_rate, logs=True)\n",
    "            model_weights.append(self.model)\n",
    "            losses.append(loss)\n",
    "            column.append(col)\n",
    "        self.models = model_weights\n",
    "        self.columns = column\n",
    "            \n",
    "        return losses\n",
    "    \n",
    "    def EL_pred(self, test_df):\n",
    "        models = self.models\n",
    "        col = self.columns\n",
    "        df_predictions = {}\n",
    "        for i in range(len(models)):\n",
    "            column_name = \"NN_{}\".format(i)\n",
    "            predictions = self.EL_predict(test_df[col[i]], models[i])\n",
    "            df_predictions[column_name] = predictions\n",
    "\n",
    "        df_predictions = pd.DataFrame(df_predictions)\n",
    "        NN_predictions = df_predictions.mode(axis=1)[0].tolist()\n",
    "\n",
    "        return NN_predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = x_train.shape[1]\n",
    "NN = NeuralNetwork(input_size=D_in, layers=10, output_size=2, random_seed=1231)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 0.1507\n",
      "Epoch 50 Loss 0.1258\n",
      "Epoch 100 Loss 0.1218\n",
      "Epoch 150 Loss 0.1208\n",
      "Epoch 200 Loss 0.1204\n",
      "Epoch 250 Loss 0.1202\n",
      "Epoch 300 Loss 0.1200\n",
      "Epoch 350 Loss 0.1199\n",
      "Epoch 400 Loss 0.1199\n",
      "Epoch 450 Loss 0.1198\n"
     ]
    }
   ],
   "source": [
    "losses = NN.train(x_train, y_train, 500, 1e-5) # learning rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is 0.9359959037378393\n"
     ]
    }
   ],
   "source": [
    "X_valid = np.array(x_valid)\n",
    "Y_valid = np.array(y_valid)\n",
    "\n",
    "outputs = NN.predict(X_valid)\n",
    "acc = NN.accuracy(Y_valid, outputs)\n",
    "WL_acc[\"NN\"] = acc\n",
    "print(f\"Training accuracy is {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights voting prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_voting(test_df, forest, RFmodel, NNmodel, WL_acc={}):\n",
    "    mean = sum(WL_acc.values()) / len(WL_acc)\n",
    "    WL_weights = {key: value / mean for key, value in WL_acc.items()}\n",
    "    preds = RFmodel.random_forest_predictions(test_df, forest)\n",
    "    T_df = np.array(test_df.iloc[:,:-1])\n",
    "    preds[\"NN\"] = NNmodel.predict(T_df)\n",
    "    p = preds.replace(0, -1)\n",
    "    pred = p.mul(pd.Series(WL_weights), axis=1)\n",
    "    result = []\n",
    "    for idx in range(pred.shape[0]):\n",
    "        y_hat = 1 if pred.iloc[idx].sum()>0 else 0\n",
    "        result.append(y_hat)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is 0.9377880184331797\n"
     ]
    }
   ],
   "source": [
    "result = weight_voting(test_x_y, forest, RFC, NN, WL_acc=WL_acc)\n",
    "accuracy = NN.accuracy(y_test, result)\n",
    "print(f\"Training accuracy is {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Ensemble of Deep Learning-Based Non-Tree Weak Learners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Learning (comparing RF & NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切割訓練集、驗證集與測試集\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test = split_data(df, y, valid_proportion=0.1, test_proportion=0.2, random_state=1121225)\n",
    "x_train.shape, x_valid.shape, x_test.shape, y_train.shape, y_valid.shape, y_test.shape\n",
    "\n",
    "# 將特徵與label合併\n",
    "train_x_y = pd.concat([x_train, y_train], axis=1)\n",
    "valid_x_y = pd.concat([x_valid, y_valid], axis=1)\n",
    "test_x_y = pd.concat([x_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standard Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [16:32<00:00, 198.54s/it]\n"
     ]
    }
   ],
   "source": [
    "feature_number = 40\n",
    "model_num = 5\n",
    "forest = RFC.random_forest_algorithm(train_x_y, n_trees=model_num, n_features=feature_number, dt_max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is 0.28793309438470727\n"
     ]
    }
   ],
   "source": [
    "pred_rf = RFC.EL_random_forest_predictions(test_x_y, forest)\n",
    "rf_acc = RFC.calculate_accuracy(y_test, pred_rf)\n",
    "print(f\"Training accuracy is {rf_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest using 2-layers MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 0.6723\n",
      "Epoch 50 Loss 0.1219\n",
      "Epoch 100 Loss 0.1207\n",
      "Epoch 150 Loss 0.1202\n",
      "Epoch 200 Loss 0.1199\n",
      "Epoch 250 Loss 0.1197\n",
      "Epoch 300 Loss 0.1196\n",
      "Epoch 350 Loss 0.1195\n",
      "Epoch 400 Loss 0.1195\n",
      "Epoch 450 Loss 0.1194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:11<00:44, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 0.1482\n",
      "Epoch 50 Loss 0.1230\n",
      "Epoch 100 Loss 0.1204\n",
      "Epoch 150 Loss 0.1198\n",
      "Epoch 200 Loss 0.1195\n",
      "Epoch 250 Loss 0.1193\n",
      "Epoch 300 Loss 0.1192\n",
      "Epoch 350 Loss 0.1192\n",
      "Epoch 400 Loss 0.1191\n",
      "Epoch 450 Loss 0.1191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:21<00:32, 10.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 0.1320\n",
      "Epoch 50 Loss 0.1209\n",
      "Epoch 100 Loss 0.1199\n",
      "Epoch 150 Loss 0.1196\n",
      "Epoch 200 Loss 0.1194\n",
      "Epoch 250 Loss 0.1193\n",
      "Epoch 300 Loss 0.1192\n",
      "Epoch 350 Loss 0.1192\n",
      "Epoch 400 Loss 0.1191\n",
      "Epoch 450 Loss 0.1191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:32<00:21, 10.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 0.1080\n",
      "Epoch 50 Loss 0.1189\n",
      "Epoch 100 Loss 0.1189\n",
      "Epoch 150 Loss 0.1189\n",
      "Epoch 200 Loss 0.1188\n",
      "Epoch 250 Loss 0.1188\n",
      "Epoch 300 Loss 0.1187\n",
      "Epoch 350 Loss 0.1187\n",
      "Epoch 400 Loss 0.1186\n",
      "Epoch 450 Loss 0.1186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:43<00:10, 10.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 0.1284\n",
      "Epoch 50 Loss 0.1202\n",
      "Epoch 100 Loss 0.1199\n",
      "Epoch 150 Loss 0.1197\n",
      "Epoch 200 Loss 0.1196\n",
      "Epoch 250 Loss 0.1195\n",
      "Epoch 300 Loss 0.1195\n",
      "Epoch 350 Loss 0.1194\n",
      "Epoch 400 Loss 0.1194\n",
      "Epoch 450 Loss 0.1193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:54<00:00, 10.88s/it]\n"
     ]
    }
   ],
   "source": [
    "ELNN = NeuralNetwork(input_size=feature_number, layers=10, output_size=2, random_seed=101)\n",
    "losses = ELNN.Ensemble_Learning(x_train, y_train, 500, 1e-5, model_num, feature_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is 0.9377880184331797\n"
     ]
    }
   ],
   "source": [
    "pred_nn = ELNN.EL_pred(x_test)\n",
    "EL_accuracy = ELNN.accuracy(y_test, pred_nn)\n",
    "print(f\"Training accuracy is {EL_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
